<?xml version="1.0"?>

<pipeline ssi-v="1">

	<register>
		<load name="graphic" />
		<load name="audio" depend="ssidialog.dll" />
		<load name="ioput" />
		<load name="signal" />
		<load name="python310" />
		<load name="opensmile" />
	</register>

	<!-- # Live input

	`audio:live=true`:
	> `audio:live:mic=true`: input from a microphone
	> `audio:live:mic=false`: output of the soundcard (make sure to set the output format of your
	soundcard to `16 bit` and `48000 Hz`)
	`audio:live=false`: input from file (`mono` and sampled at `48000 Hz`)

	![](https://raw.githubusercontent.com/hcmlab/vadnet/master/pics/loopback.png)	
	
	-->
	<gate open="$(audio:live)">
		<gate open="$(audio:live:mic)">
			<sensor create="Audio" option="options\microphone" sr="48000" scale="true"
				blockInSamples="416">
				<output channel="audio" pin="audio" />
			</sensor>
		</gate>
		<gate close="$(audio:live:mic)">
			<sensor create="AudioLoopBack" option="options\loopback" scale="true">
				<output channel="audio" pin="audio">
					<transformer create="Selector" indices="0" />
				</output>
			</sensor>
		</gate>
	</gate>

	<gate close="$(audio:live)">
		<sensor create="WavReader:reader" path="..\data\speech.wav" loop="true">
			<output channel="audio" pin="audio" size="2.0s" />
		</sensor>
	</gate>
	<!---->

	<!-- # Preprocessing
	> Pitch: `OSPitchShs` (filter)
	> Loudness: `OSIntensity` (feature)
	-->
	<transformer create="DownSample" keep="4">
		<input pin="audio" frame="9"/>
		<output pin="audio-down"/>
	</transformer>
	<transformer create="OSPitchChain" option="pitch">
		<input pin="audio-down" frame="0.01s" delta="0.02s"/>
		<output pin="audio-pitch"/>
	</transformer>
	<gate open="$(audio:mffc)">
		<transformer create="OSMfccChain" option="mfcc">
			<input pin="audio-down" frame="0.01s" delta="0.02s"/>
			<output pin="audio-mfcc"/>
		</transformer>
	</gate>
	<transformer create="OSIntensity" intensity="0" loudness="1">
		<input pin="audio-down" frame="0.3s" />
		<output pin="audio-loudness" />
	</transformer>
	<!---->

	<!-- # Playback and Visualization
	
	Finally, we play back the audio signal (in case of file input only) and visualize it.	
	
	-->
	<gate close="$(audio:live)">
		<consumer create="AudioPlayer" option="options\aplayer">
			<input pin="audio" frame="0.1s" />
		</consumer>
	</gate>
	<consumer create="SignalPainter:plot" title="AUDIO" size="10" type="2">
		<input pin="audio" frame="0.3s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" title="LOUDNESS" size="10.0" type="5" colormap="3">
		<input pin="audio-loudness" frame="0.3s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="pitch" type="5">
		<input pin="audio-pitch" frame="0.02s" />
	</consumer>
	<gate open="$(audio:mffc)">
		<consumer create="SignalPainter:plot-mffc" size="10" title="MFCC" type="1">
			<input pin="audio-mfcc" frame="0.03s" />
		</consumer>
	</gate>
	<!--<consumer create="PythonConsumer:plot-data" script="audio_visualization" optsstr="title=Loudness">
		<input pin="audio-loudness" frame="0.2s"/>
	</consumer>
	<consumer create="PythonConsumer:plot-data" script="audio_visualization" optsstr="title=Loudness">
		<input pin="audio-loudness" frame="0.2s"/>
	</consumer>-->
	
	<!-- decoration -->
	<gate close="$(audio:mffc)">
		<object create="Decorator" icon="true" title="Pipeline">
			<area pos="0,0,400,600">console</area>
			<area pos="400,0,400,300">plot</area>
			<area pos="400,400,400,300" nv="1" nh="2">plot-data*</area>
		</object>
	</gate>
	<gate open="$(audio:mffc)">
		<object create="Decorator" icon="true" title="Pipeline">
			<area pos="0,0,400,600">console</area>
			<area pos="400,0,400,300">plot</area>
			<area pos="400,400,400,300" nv="1" nh="2">plot-data*</area>
			<area pos="800,400,400,300">plot-mffc</area>
		</object>
	</gate>
	<!---->

</pipeline>