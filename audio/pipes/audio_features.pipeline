<?xml version="1.0"?>

<pipeline ssi-v="1">

	<register>
		<load name="graphic" />
		<load name="signal" />
		<load name="python310" />
		<load name="opensmile" />
	</register>

	<include path=".\audio_input.pipeline"/>

	<!-- # Downsample and VAD
	The audio input is downsampled to `16000 Hz` and the VAD is applied to the downsampled signal.
	The VAD is implemented in Python and is based on the `silero_vad` library. The VAD is used to detect speech segments in the audio signal.
	The VAD output is used to filter the audio signal and to extract features only from the speech segments (0 values otherwise).
	-->
	<transformer create="DownSample" keep="3">
		<input pin="audio" frame="9"/>
		<output pin="audio-down"/>
	</transformer>

	<transformer create="PythonFeature" script="vad" syspath="..\scripts">
		<input pin="audio-down" frame="0.1s"/>
		<output pin="python-vad"/>
	</transformer>
	
	<transformer create="PythonFilter" script="vad_filter" syspath="..\scripts">
		<input pin="audio-down" frame="0.1s"/>
		<listen address="vad@audio"/>
		<output pin="vad-audio"/>
	</transformer>
	<!---->

	<!-- # Preprocessing with OpenSMILE
	
	Here we use the OpenSMILE library to extract features from the audio signal.
	We extract the following features:
	- Pitch: `PythonFeature` (filter)
	- Energy: `OSEnergy` (feature)
	- Loudness: `PythonFeature` (feature)
	- Jitter: `PythonFeature` (feature)
	- Shimmer: `PythonFeature` (feature)
	- Alpha Ratio: `PythonFeature` (feature)
	- Hammarberg Index: `PythonFeature` (feature)
	- Spectral Flux: `PythonFeature` (feature)
	- Spectral Slope 0-500: `PythonFeature` (feature)
	- MFCC: `OSMfccChain` (feature, optional if `features:mffc=true`)
	-->
	<transformer create="OSEnergy">
		<input pin="vad-audio" frame="0.3s" delta="0.15s"/>
		<output pin="energy"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=loudness_sma3_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="loudness" pin="loudness"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=F0semitoneFrom27.5Hz_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="pitch" pin="pitch"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=jitterLocal_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="jitter" pin="jitter"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=shimmerLocaldB_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="shimmer" pin="shimmer"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=alphaRatioV_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output pin="alpha-ratio"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=hammarbergIndexV_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="hammarberg-index" pin="hammarberg-index"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=spectralFluxV_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="spectral-flux" pin="spectral-flux"/>
	</transformer>
	<transformer create="PythonFeature" script="opensmile_manager" syspath="..\scripts" optsstr="feature=slopeV0-500_sma3nz_amean">
		<input pin="audio-down" frame="1s" delta="0.5s"/>
		<output channel="spectral-slope" pin="spectral-slope"/>
	</transformer>
	<gate open="$(features:mffc)">
		<transformer create="OSMfccChain" option="..\options\mfcc">
			<input pin="vad-audio" frame="0.01s" delta="0.02s"/>
			<output pin="mfcc"/>
		</transformer>
	</gate>

	<object create="EventMonitor:monitor" title="Events">
		<listen address="vad@audio" span="10000"/>
	</object>
	<!---->

	<!-- # Playback and Visualization
	
	Then we play back the audio signal and visualize its informations.
	
	-->
	<gate close="$(audio:live)">
		<consumer create="AudioPlayer" option="..\options\aplayer">
			<input pin="audio" frame="0.1s" />
		</consumer>
	</gate>
	<consumer create="SignalPainter:plot" title="AUDIO" size="10" type="2">
		<input pin="audio" frame="0.3s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" title="LOUDNESS" size="10.0" type="5" colormap="3">
		<input pin="loudness" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" title="PITCH" type="5">
		<input pin="pitch" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="ENERGY" type="4">
		<input pin="energy" frame="0.3s" delta="0.15s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" title="JITTER" type="5">
		<input pin="jitter" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" title="SHIMMER" type="5">
		<input pin="shimmer" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="ALPHA RATIO" type="4">
		<input pin="alpha-ratio" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="HAMMARBERG INDEX" type="4">
		<input pin="hammarberg-index" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="SPECTRAL SLOPE" type="4">
		<input pin="spectral-slope" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plot-data" size="10" title="SPECTRAL FLUX" type="5">
		<input pin="spectral-flux" frame="1s" delta="0.5s" />
	</consumer>
	<consumer create="SignalPainter:plota" title="VAD" size="10" type="2">
		<input pin="vad-audio" frame="0.1s" />
	</consumer>
	<gate open="$(features:mffc)">
		<consumer create="SignalPainter:plot-mffc" size="10" title="MFCC" type="1">
			<input pin="mfcc" frame="0.03s" />
		</consumer>
	</gate>

	<gate close="$(features:mffc)">
		<object create="Decorator" icon="true" title="Pipeline">
			<area pos="0,0,400,300">plot</area>
			<area pos="0,300,600,600" nv="2" nh="5">plot-data*</area>
			<area pos="400,0,400,300">plota</area>
			<area pos="900,0,600,800">monitor</area>
		</object>
	</gate>
	<gate open="$(features:mffc)">
		<object create="Decorator" icon="true" title="Pipeline">
			<area pos="0,0,400,300">plot</area>
			<area pos="0,300,600,600" nv="2" nh="5">plot-data*</area>
			<area pos="400,0,400,300">plota</area>
			<area pos="600,300,400,300">plot-mffc</area>
			<area pos="1100,0,400,800">monitor</area>
		</object>
	</gate>
	<!---->

	<!-- # Storage of features
	
	Finally, if specified by the config variable `output:file:save` (eventually specifying also if you want a new file with `output:file:new`), the features are stored in a file (path specified in `output:file:path`).
	The config variable `user:class` is used to specify the class/identifier of the user.
	All values of features with the lower framerate are saved. Instead, features with higher framerate are first filtered with savgolf_filter and then averaged to obtain values in correspondence of the ones just mentioned.
	
	-->
	<gate open="$(output:file:save)">
		<consumer create="PythonConsumer" script="file_storage" syspath="..\scripts" optsstr="user_class=$(user:class);file_path=$(output:file:path);new_file=$(output:file:new)">
			<input pin="loudness" frame="1s" delta="0.15s" />
			<xinput size="7">
				<input pin="pitch" />
				<input pin="energy" />
				<input pin="jitter" />
				<input pin="shimmer" />
				<input pin="alpha-ratio" />
				<input pin="hammarberg-index" />
				<input pin="spectral-flux" />
				<input pin="spectral-slope" />
			</xinput>
		</consumer>
	</gate>
	<!---->

</pipeline>