{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Setup MediaPipe Holistic instance\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Setup drawing utility\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Setup MediaPipe Holistic instance\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Setup drawing utility\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Make Detections\n",
    "cap = cv2.VideoCapture(0)\n",
    "start_time = None\n",
    "\n",
    "# If exists previous data, delete it\n",
    "if os.path.exists(\"landmarks.stream\"):\n",
    "    os.remove(\"landmarks.stream\")\n",
    "with open(\"landmarks.stream\", \"a+\") as f:\n",
    "\n",
    "\n",
    "    with holistic as pose:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False        \n",
    "            \n",
    "            # Make Detections\n",
    "            results = holistic.process(image)\n",
    "            \n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True   \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Extract elbow landmarks\n",
    "            # try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            #0\n",
    "            nose = [landmarks[mp_holistic.PoseLandmark.NOSE.value].x,\n",
    "                    landmarks[mp_holistic.PoseLandmark.NOSE.value].y]\n",
    "            #13, 14\n",
    "            left_elbow = [landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            right_elbow = [landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            #15, 16\n",
    "            left_wrist = [landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            right_wrist = [landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            #11, 12\n",
    "            left_shoulder = [landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                                landmarks[mp_holistic.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            right_shoulder = [landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                                landmarks[mp_holistic.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            #23, 24\n",
    "            left_hip = [landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].x,\n",
    "                        landmarks[mp_holistic.PoseLandmark.LEFT_HIP.value].y]\n",
    "            right_hip = [landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            #17, 18\n",
    "            left_pinky = [landmarks[mp_holistic.PoseLandmark.LEFT_PINKY.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.LEFT_PINKY.value].y]\n",
    "            right_pinky = [landmarks[mp_holistic.PoseLandmark.RIGHT_PINKY.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.RIGHT_PINKY.value].y]\n",
    "            #19, 20\n",
    "            left_index = [landmarks[mp_holistic.PoseLandmark.LEFT_INDEX.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.LEFT_INDEX.value].y]\n",
    "            right_index = [landmarks[mp_holistic.PoseLandmark.RIGHT_INDEX.value].x,\n",
    "                            landmarks[mp_holistic.PoseLandmark.RIGHT_INDEX.value].y]\n",
    "            \n",
    "\n",
    "            #print(\"nose: \", (1-nose[1]))\n",
    "            \n",
    "            #save data into .stream file\n",
    "            \n",
    "            f.write(str(1-nose[1]) + \"\\n\")\n",
    "            f.flush()   \n",
    "            os.fsync(f.fileno())   #flush the buffer            \n",
    "            \n",
    "            # Extract Pose landmarks for AI sulution\n",
    "            # pose = results.pose_landmarks.landmark       \n",
    "            # pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())         \n",
    "            # # Extract Face landmarks\n",
    "            # face = results.face_landmarks.landmark\n",
    "            # face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())        \n",
    "            # # Concate rows\n",
    "            # row = pose_row+face_row\n",
    "            \n",
    "            # # Make Detections for AI solution\n",
    "            # x = pd.DataFrame([row])\n",
    "            # model_class = model.predict(x)[0] #class of the model\n",
    "            # model_prob = model.predict_proba(x)[0] #probability of each class\n",
    "            # #print(model_class, model_prob)\n",
    "            # actual_stage = model_class\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            # Render landmarks\n",
    "            # 1. Draw face landmarks\n",
    "            mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "                                    )\n",
    "\n",
    "            # 2. Right hand\n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(80, 44, 121), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "\n",
    "            # 3. Left Hand\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "\n",
    "            # 4. Pose Detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                    mp_drawing.DrawingSpec(\n",
    "                                        color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                    )\n",
    "\n",
    "            cv2.imshow('MediaPipe Feed', image)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
